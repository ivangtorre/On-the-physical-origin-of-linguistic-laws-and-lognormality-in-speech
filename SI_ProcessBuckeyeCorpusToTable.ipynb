{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process para Buckeye\n",
    "Este script procesa la base de datos de Buckeye y la convierte a una tabla. La tabla actuamente tiene los siguientes campos:\n",
    "token: la palabra o fonema\n",
    "duracion: duracion de la palabra o fonema\n",
    "path: fichero de donde se ha extraido\n",
    "type: w (word) o p (phonema)\n",
    "numtoken: una etiqueta para saber que fonemas pertenecen a que palabra\n",
    "\n",
    "Falta por hacer:\n",
    "Extraer energia\n",
    "Contador numero de frases. Decidir que es una frase\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importar_align_words(path):\n",
    "    \"\"\"\n",
    "    Buscar fichero words en un path\n",
    "    \"\"\"\n",
    "    fichero_words = glob.glob(path + \"*.words\")\n",
    "    if len(fichero_words) == 1:\n",
    "        #print(\"ok\")\n",
    "        pass\n",
    "    else:\n",
    "        sys.exit(\"Error importar fichero words\")\n",
    "        \n",
    "    words_align = pd.read_csv(fichero_words[0], sep = ' 122 ' , skiprows=9, header=None,\n",
    "                              names=[\"t_end\", \"token\"], engine='python')\n",
    "\n",
    "    df = pd.DataFrame(words_align.token.str.split(';').tolist(),\n",
    "                      columns = [\"token\", \"phoneme1\", \"phoneme2\", \"phoneme3\"])\n",
    "    words_align = pd.concat([words_align.t_end.reset_index(drop=True),df.reset_index(drop=True)], axis=1)\n",
    "    return(words_align)\n",
    "\n",
    "\n",
    "def importar_sentences(path):\n",
    "    \"\"\"\n",
    "    Buscar fichero words en un path\n",
    "    \"\"\"\n",
    "    sentences = glob.glob(path + \"*.txt\")\n",
    "    if len(sentences) == 1:\n",
    "        #print(\"ok\")\n",
    "        pass\n",
    "    else:\n",
    "        sys.exit(\"Error importar fichero words\")\n",
    "        \n",
    "    sentences_align = pd.read_csv(sentences[0], sep = ' 122 ' , skiprows=9, header=None,\n",
    "                              names=[\"t_end\", \"token\"], engine='python')\n",
    "\n",
    "    df = pd.DataFrame(words_align.token.str.split(';').tolist(),\n",
    "                      columns = [\"token\", \"phoneme1\", \"phoneme2\", \"phoneme3\"])\n",
    "    words_align = pd.concat([words_align.t_end.reset_index(drop=True),df.reset_index(drop=True)], axis=1)\n",
    "    return(words_align)\n",
    "\n",
    "\n",
    "\n",
    "def importar_align_phoneme(path):\n",
    "    \"\"\"\n",
    "    Buscar fichero words en un path\n",
    "    \"\"\"\n",
    "    fichero_words = glob.glob(path + \"*.phones\")\n",
    "    if len(fichero_words) == 1:\n",
    "        #print(\"ok\")\n",
    "        pass\n",
    "    else:\n",
    "        sys.exit(\"Error importar fichero words\")\n",
    "        \n",
    "    phones_align = pd.read_csv(fichero_words[0], sep = '  ' , skiprows=9, header=None, names=[\"t_end\", \"token\"], engine='python')\n",
    "    df = pd.DataFrame(phones_align.token.str.split(' ', 1).tolist(), columns = [\"chunk\", \"token\"])\n",
    "    phones_align = pd.concat([phones_align.t_end.reset_index(drop=True),df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    return(phones_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener todas las subcarpetas\n",
    "folders = [(root[2::] + \"/\" ) for root, dirs, files in os.walk('.') if not dirs and bool(re.match('^[sabcdfe0-9_/.-]*$', root))]\n",
    "folders.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Convertir fichero en frases uno de los folders unicamente\n",
    "sentences_path = glob.glob(folders[0] + \"*.txt\")\n",
    "sentence_raw = pd.read_csv(sentences_path[0], skiprows=0, header=None, names=[\"sentence\"], engine='python')\n",
    "\n",
    "sentences  = sentence_raw[\"sentence\"].str.split(\"<SIL>\", expand = True).stack()\n",
    "sentences = sentences.str.replace(r\"\\<.*\\>\", '') # Regular expresion remove all comments\n",
    "sentences\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a = sentences.reset_index()\n",
    "# Remove Empty lines\n",
    "a[0].replace('', np.nan, inplace=True)\n",
    "a[0].replace(' ', np.nan, inplace=True)\n",
    "a.dropna(subset=[0], inplace=True)\n",
    "a = a.reset_index()\n",
    "a  = a[0].str.split(\" \", expand = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_token = 0\n",
    "lista_token = []\n",
    "lista_tinit = []\n",
    "lista_tend = []\n",
    "lista_duration = []\n",
    "lista_numphonemes = []\n",
    "lista_numletters = []\n",
    "lista_sentence = []\n",
    "\n",
    "lista_file = []\n",
    "lista_type = [] # word or phoneme\n",
    "lista_numtoken = []\n",
    "\n",
    "sentence_flag = 0\n",
    "\n",
    "for path in folders:\n",
    "    print(path)\n",
    "    \n",
    "    # Tabla phonemas y palabras\n",
    "    words_align = importar_align_words(path)\n",
    "    phones_align = importar_align_phoneme(path)\n",
    "    \n",
    "    \n",
    "    # Procesamos los datos \n",
    "    for index, row in words_align.iterrows():\n",
    "        # Si hay un silencio (SIL) o habla en entrevistador (IVER) or aspiraciones (VOCNOISE), cambio de frase\n",
    "        if (row.token == \"<SIL>\") or (row.token == \"<IVER>\") or (row.token == \"<VOCNOISE>\"):\n",
    "            sentence_flag += 1\n",
    "\n",
    "        if ((row.token.startswith(\"<\") == False) and (row.token.endswith(\">\") == False) and \n",
    "            (row.token.startswith(\"{\") == False) and (row.token.endswith(\"}\") == False) and\n",
    "            (row.phoneme2 != None) and (row.phoneme2.strip().split(\" \") != [\"\"])):\n",
    "            num_token += 1\n",
    "            \n",
    "            ########################################################################################\n",
    "            # WORDS ################################################################################\n",
    "            lista_numtoken.append(num_token)\n",
    "            lista_token.append(row.token)\n",
    "            lista_file.append(path)\n",
    "            lista_type.append(\"w\")\n",
    "            lista_numphonemes.append(len(row.phoneme2.strip().split(\" \")))\n",
    "            lista_numletters.append(len(row.token))\n",
    "            lista_sentence.append(sentence_flag)\n",
    "\n",
    "            \n",
    "            \n",
    "            # Duracion word\n",
    "            lista_tinit.append(words_align.loc[index-1].t_end)\n",
    "            lista_tend.append(words_align.loc[index].t_end)\n",
    "            lista_duration.append(words_align.loc[index].t_end - words_align.loc[index-1].t_end) #Fin del actual - Fin del anterior\n",
    "            \n",
    "            # Energia word\n",
    "            \n",
    "            \n",
    "            # Frase\n",
    "            \n",
    "            \n",
    "            #######################################################################################\n",
    "            # ALINEAMIENTO PHONEMAS ###############################################################\n",
    "            ########################################################################################\n",
    "            phonemes = row.phoneme2.strip().split(\" \") # Convierte fonemas en lista\n",
    "            if phonemes[0] == 'SIL': # Si han colado un silencio lo eliminamos (BUG corregido)\n",
    "                phonemes.pop(0)\n",
    "            \n",
    "            \n",
    "            # Search primer fonema\n",
    "            # BUGS: No coincide el tiempo exacto. Se busca el mas cercano\n",
    "            # No coincide el phonema exactamente, se filtra\n",
    "            idx_init = (np.abs(phones_align.t_end - words_align.loc[index-1].t_end)).idxmin() +1\n",
    "            if (phones_align.loc[idx_init].token.split(\";\")[0].strip().split(\"+1\")[0] != phonemes[0]): # En caso de no coincidir\n",
    "                tempdf = (np.abs(phones_align.t_end - words_align.loc[index-1].t_end)).nsmallest(6)\n",
    "                idx_init = phones_align.loc[tempdf.index].token[phones_align.loc[tempdf.index].token.str.split(\" ;\", expand=True)[0] == phonemes[0]].index[0]\n",
    "                print(\"exception1\")\n",
    "\n",
    "            # Search ultimo fonema\n",
    "            idx_end = (np.abs(phones_align.t_end - words_align.loc[index].t_end)).idxmin()\n",
    "            if phones_align.loc[idx_end].token == None:\n",
    "                idx_end = idx_end-1\n",
    "            if (phones_align.loc[idx_end].token.split(\";\")[0].strip().split(\"+1\")[0] != phonemes[-1]): # En caso de no coincidir\n",
    "                tempdf = (np.abs(phones_align.t_end - words_align.loc[index].t_end)).nsmallest(4)\n",
    "                idx_end = phones_align.loc[tempdf.index].token[phones_align.loc[tempdf.index].token.str.split(\" ;\", expand=True)[0] == phonemes[-1]].index[0]\n",
    "                print(\"exception2\")\n",
    "                \n",
    "            if ((phones_align.loc[idx_init].token.split(\";\")[0].strip().split(\"+1\")[0] == phonemes[0]) & \n",
    "                (phones_align.loc[idx_end].token.split(\";\")[0].strip().split(\"+1\")[0] == phonemes[-1])):\n",
    "                for idp in range(idx_init, idx_end+1):\n",
    "                    pass\n",
    "                    #print(phones_align.loc[idp].token)\n",
    "            else:\n",
    "                sys.exit(\"Error buscando fonemas de la palabra\")\n",
    "            \n",
    "            # MEDIDAS FONEMA ####################################################\n",
    "            for idp in range(idx_init, idx_end+1):\n",
    "                # A veces hay marcas vacias\n",
    "                if phones_align.loc[idp].token != None:\n",
    "                    lista_numtoken.append(num_token)\n",
    "                    phontoken = phones_align.loc[idp].token.split(\";\")[0].strip().split(\"+1\")[0]\n",
    "                    lista_token.append(phontoken)\n",
    "                    lista_file.append(path)\n",
    "                    lista_sentence.append(sentence_flag)\n",
    "\n",
    "                    lista_type.append(\"p\")\n",
    "                    lista_numphonemes.append(1)\n",
    "                    if phones_align.loc[idp].token != None:\n",
    "                        lista_numletters.append(len(phones_align.loc[idp].token))\n",
    "                    else:\n",
    "                        lista_numletters.append(0)\n",
    "                        \n",
    "\n",
    "                \n",
    "                    # DURACION DEL FONEMA\n",
    "                    lista_tinit.append(phones_align.loc[idp-1].t_end)\n",
    "                    lista_tend.append(phones_align.loc[idp].t_end)\n",
    "                    lista_duration.append(phones_align.loc[idp].t_end - phones_align.loc[idp-1].t_end) #Fin del actual - Fin del anterior\n",
    "\n",
    "            \n",
    "            \n",
    "    # Each time we save the data\n",
    "    tablaResumen = pd.DataFrame({\"token\":lista_token, \"tinit\":lista_tinit, \"tend\":lista_tend, \n",
    "                                \"duration\":lista_duration, \"sentence\": lista_sentence, \"path\": lista_file,\n",
    "                                \"type\": lista_type, \"numtoken\": lista_numtoken, \"numphonemes\":lista_numphonemes,\n",
    "                                \"numletters\": lista_numletters})\n",
    "    tablaResumen.to_csv(\"TablaTranscripcion.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
